
This repo is for the experiments on sentence and word tokenization.

The jupyter notebook (`Tokenisation.ipynb`) is the main file.

The maxmatch.py module engineers the maxmatch algorithm and some other utilities.

Thanks.